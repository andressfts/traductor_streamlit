import os
import streamlit as st
import torch
from transformers import MarianTokenizer, MarianMTModel

# (opcional) Prevenir fallos en compilaci√≥n con tensores meta
os.environ["TORCH_COMPILE_UNSUPPORTED_DEVICE_FALLBACK"] = "1"

# Ruta del modelo entrenado
model_path = "./modelo_personalizado"

# Cargar tokenizer y modelo (todo en CPU, sin .to(device))
tokenizer = MarianTokenizer.from_pretrained(model_path)
model = MarianMTModel.from_pretrained(model_path)

# T√≠tulo
st.title("Traductor Personalizado Espa√±ol ‚Üí Ingl√©s")
st.write("Este traductor usa un modelo entrenado con frases espec√≠ficas.")

# Entrada
texto = st.text_area("Escribe en espa√±ol:", "Buenos d√≠as")

# Traducci√≥n
if st.button("Traducir"):
    if texto.strip():
        with st.spinner("Traduciendo..."):
            tokens = tokenizer(texto, return_tensors="pt", padding=True)
            tokens = {k: v for k, v in tokens.items()}  # üîÅ No mover a otro device
            traduccion_ids = model.generate(**tokens)
            traduccion = tokenizer.decode(traduccion_ids[0], skip_special_tokens=True)
            st.success("‚úÖ Traducci√≥n completada")
            st.text_area("Traducci√≥n:", traduccion, height=100)
    else:
        st.warning("Por favor ingresa un texto.")
